############################################
# SERVING PARAMETERS
############################################
# "http" or "task" or "websocket"
SERVICE_MODE=http

# Below: used when SERVICE_MODE=task
SERVICE_NAME=stt
SERVICES_BROKER=redis://172.17.0.1:6379
BROKER_PASS=

# Below: used when SERVICE_MODE=websocket
STREAMING_PORT=80

############################################
# STT MODELING PARAMETERS
############################################

MODEL=nvidia/parakeet-tdt-0.6b-v2
ARCHITECTURE=rnnt_bpe

# MODEL=linagora/linto_stt_fr_fastconformer
# ARCHITECTURE=hybrid_bpe
# For streaming only:
# PUNCTUATION_MODEL=

# MODEL=nvidia/stt_fr_fastconformer_hybrid_large_pc
# ARCHITECTURE=hybrid_bpe

VAD=auditok
VAD_DILATATION=0.5                # Time to add before and after the detected speech
VAD_MIN_SPEECH_DURATION=0.1       # Minimum duration of speech to keep
VAD_MIN_SILENCE_DURATION=0.1      # Minimum duration of silence to keep

############################################
# FILE TRANSCRIPTION (HTTP and TASK MODES)
############################################

# These models can't handle files that are too long, so it must be split if too long
# 540s=9mins. A file longer than that will be split into smaller parts. This value depends on your VRAM/RAM amount
LONG_FILE_THRESHOLD=540
# 360s=6min. Size of the parts into which the audio is splitted. This value depends on your VRAM/RAM amount
LONG_FILE_CHUNK_LEN=360
# 5s of context at the begining and end of each chunk
LONG_FILE_CHUNK_CONTEXT_LEN=5

############################################
# STREAMING PARAMETERS (WEBSOCKET MODE)
############################################

STREAMING_MIN_CHUNK_SIZE=0.5
STREAMING_BUFFER_TRIMMING_SEC=10
STREAMING_PAUSE_FOR_FINAL=1.2
STREAMING_TIMEOUT_FOR_SILENCE=
STREAMING_MAX_WORDS_IN_BUFFER=5
STREAMING_MAX_PARTIAL_ACTUALIZATION_PER_SECOND=4

############################################
# EFFICIENCY PARAMETERS
############################################

# Device to use. It can be "cuda" to force/check GPU, "cpu" to force computation on CPU, or a specific GPU ("cuda:0", "cuda:1", ...)
DEVICE=

# NVIDIA_VISIBLE_DEVICES=0
# NVIDIA_DRIVER_CAPABILITIES=all
# CUDA_DEVICE_ORDER=PCI_BUS_ID
# CUDA_VISIBLE_DEVICES=0

# Number of threads per worker when running on CPU
NUM_THREADS=

# Number of workers minus one (all except from the main one), for http and task modes
CONCURRENCY=1

############################################
# USERS AND GROUPS
############################################

USER_ID=1000
GROUP_ID=1000